{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document classification with LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Machine Learning',\n",
       " 'Money fun Family Kids home',\n",
       " 'Programming Java Data Structures',\n",
       " 'Love food health games energy fun',\n",
       " 'Algorithms Data Computers']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = \"Data Science Machine Learning\"\n",
    "doc2 = \"Money fun Family Kids home\"\n",
    "doc3 = \"Programming Java Data Structures\"\n",
    "doc4 = \"Love food health games energy fun\"\n",
    "doc5 = \"Algorithms Data Computers\"\n",
    "\n",
    "# combine documents\n",
    "doc_complete = [doc1, doc2, doc3, doc4, doc5]\n",
    "doc_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf–idf or TFIDF(term frequency–inverse document frequency) is Vectorizer like GloVe and word2vec,\n",
    "# is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tf–idf](images/tfidf.png \"tf-idf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(doc_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t0.3606383263504801\n",
      "  (0, 17)\t0.5384979101064753\n",
      "  (0, 14)\t0.5384979101064753\n",
      "  (0, 12)\t0.5384979101064753\n",
      "  (1, 15)\t0.4636932227319092\n",
      "  (1, 6)\t0.3741047724501572\n",
      "  (1, 4)\t0.4636932227319092\n",
      "  (1, 11)\t0.4636932227319092\n",
      "  (1, 9)\t0.4636932227319092\n",
      "  (2, 2)\t0.3606383263504801\n",
      "  (2, 16)\t0.5384979101064753\n",
      "  (2, 10)\t0.5384979101064753\n",
      "  (2, 18)\t0.5384979101064753\n",
      "  (3, 6)\t0.3393931489111758\n",
      "  (3, 13)\t0.4206690600631704\n",
      "  (3, 5)\t0.4206690600631704\n",
      "  (3, 8)\t0.4206690600631704\n",
      "  (3, 7)\t0.4206690600631704\n",
      "  (3, 3)\t0.4206690600631704\n",
      "  (4, 2)\t0.42799292268317357\n",
      "  (4, 0)\t0.6390704413963749\n",
      "  (4, 1)\t0.6390704413963749\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncated SVD (LSA) Implementation - Its a dimentionality reduction technique\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa = TruncatedSVD(n_components=2,n_iter=100) # n_components : number of topics we want to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=2, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.35943318e-01,  3.35943318e-01,  5.84606260e-01,\n",
       "        -1.14765359e-16,  3.50368019e-16, -1.14765359e-16,\n",
       "         1.90082786e-16, -1.14765359e-16, -1.14765359e-16,\n",
       "         3.50368019e-16,  2.68489508e-01,  3.50368019e-16,\n",
       "         2.68489508e-01, -1.14765359e-16,  2.68489508e-01,\n",
       "         3.50368019e-16,  2.68489508e-01,  2.68489508e-01,\n",
       "         2.68489508e-01],\n",
       "       [ 4.89093390e-15,  4.98647635e-15,  2.32718414e-16,\n",
       "         2.80200990e-01,  3.08858703e-01,  2.80200990e-01,\n",
       "         4.75249652e-01,  2.80200990e-01,  2.80200990e-01,\n",
       "         3.08858703e-01, -4.51068978e-15,  3.08858703e-01,\n",
       "        -5.19514974e-17,  2.80200990e-01, -5.19514974e-17,\n",
       "         3.08858703e-01, -4.51068978e-15, -5.19514974e-17,\n",
       "        -4.51068973e-15]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithms',\n",
       " 'computers',\n",
       " 'data',\n",
       " 'energy',\n",
       " 'family',\n",
       " 'food',\n",
       " 'fun',\n",
       " 'games',\n",
       " 'health',\n",
       " 'home',\n",
       " 'java',\n",
       " 'kids',\n",
       " 'learning',\n",
       " 'love',\n",
       " 'machine',\n",
       " 'money',\n",
       " 'programming',\n",
       " 'science',\n",
       " 'structures']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "data\n",
      "computers\n",
      "algorithms\n",
      "java\n",
      "programming\n",
      "structures\n",
      "learning\n",
      "machine\n",
      "science\n",
      "family\n",
      " \n",
      "Concept 1:\n",
      "fun\n",
      "family\n",
      "home\n",
      "kids\n",
      "money\n",
      "energy\n",
      "food\n",
      "games\n",
      "health\n",
      "love\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# displaying words classified in 2 topics\n",
    "for i,comp in enumerate(lsa.components_):\n",
    "    termsInComp = zip(terms,comp) # coiombines 2 three dimentional arrays to {(1, 'one'), (3, 'three'), (2, 'two')}\n",
    "    sortedterms = sorted(termsInComp, key=lambda x: x[1],reverse=True)[:10]\n",
    "    print(\"Concept %d:\" % i)\n",
    "    for term in sortedterms:\n",
    "        print(term[0])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Explained variance of the SVD step: 31%\n"
     ]
    }
   ],
   "source": [
    "explained_variance = lsa.explained_variance_ratio_.sum()\n",
    "print(\"  Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks\n",
    "LSA is quick and efficient to use, but it does have a few primary drawbacks:\n",
    "\n",
    "* lack of interpretable embeddings (we don’t know what the topics are, and the components may be arbitrarily positive/negative)\n",
    "* need for really large set of documents and vocabulary to get accurate results\n",
    "* less efficient representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:<br>\n",
    "https://github.com/chrisjmccormick/LSA_Classification <br>\n",
    "https://github.com/kernelmachine/pyLSA/blob/master/lsa.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
