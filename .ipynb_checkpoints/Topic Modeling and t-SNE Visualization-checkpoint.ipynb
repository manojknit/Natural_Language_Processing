{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling and t-SNE Visualization\n",
    "Ref:\n",
    "https://shuaiw.github.io/2016/12/22/topic-modeling-and-tsne-visualzation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic models are a suite of algorithms/statistical models that uncover the hidden topics in a collection of documents.**\n",
    "Popular topic modeling algorithms incldue latent semantic analysis (LSA), hierarchical Dirichlet process (HDP), and latent Dirichlet allocation (LDA), among which LDA has shown great results in practice and therefore been widely adopted. <br>\n",
    "**gensim library:**  Great for modeling topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "t-SNE, or t-distributed stochastic neighbor embedding, is a dimensionality reduction algorithm for high-dimensional data visualization. This is partly to mitigate the fact that human cannot (at least not now) perceive vector space that is beyond 3-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# we only want to keep the body of the documents!\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "# fetch train and test data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=remove)\n",
    "\n",
    "# a list of 18,846 cleaned news in string format\n",
    "# only keep letters & make them all lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " news = [' '.join(filter(None, raw.lower().split())) for raw in\n",
    "          newsgroups_train.data + newsgroups_test.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 18846\n",
      "INFO:lda:vocab_size: 24164\n",
      "INFO:lda:n_words: 1721127\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "/Users/mk194903/anaconda3/lib/python3.6/site-packages/lda/utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -21729674\n",
      "INFO:lda:<10> log likelihood: -15795438\n",
      "INFO:lda:<20> log likelihood: -14977411\n",
      "INFO:lda:<30> log likelihood: -14738638\n",
      "INFO:lda:<40> log likelihood: -14629942\n",
      "INFO:lda:<50> log likelihood: -14566211\n",
      "INFO:lda:<60> log likelihood: -14524718\n",
      "INFO:lda:<70> log likelihood: -14491442\n",
      "INFO:lda:<80> log likelihood: -14472611\n",
      "INFO:lda:<90> log likelihood: -14457321\n",
      "INFO:lda:<100> log likelihood: -14443151\n",
      "INFO:lda:<110> log likelihood: -14434205\n",
      "INFO:lda:<120> log likelihood: -14424413\n",
      "INFO:lda:<130> log likelihood: -14417094\n",
      "INFO:lda:<140> log likelihood: -14410215\n",
      "INFO:lda:<150> log likelihood: -14403969\n",
      "INFO:lda:<160> log likelihood: -14400224\n",
      "INFO:lda:<170> log likelihood: -14395670\n",
      "INFO:lda:<180> log likelihood: -14395191\n",
      "INFO:lda:<190> log likelihood: -14392798\n",
      "INFO:lda:<200> log likelihood: -14390439\n",
      "INFO:lda:<210> log likelihood: -14388373\n",
      "INFO:lda:<220> log likelihood: -14388573\n",
      "INFO:lda:<230> log likelihood: -14385888\n",
      "INFO:lda:<240> log likelihood: -14384165\n",
      "INFO:lda:<250> log likelihood: -14378937\n",
      "INFO:lda:<260> log likelihood: -14378908\n",
      "INFO:lda:<270> log likelihood: -14377081\n",
      "INFO:lda:<280> log likelihood: -14375572\n",
      "INFO:lda:<290> log likelihood: -14370785\n",
      "INFO:lda:<300> log likelihood: -14371475\n",
      "INFO:lda:<310> log likelihood: -14367888\n",
      "INFO:lda:<320> log likelihood: -14368182\n",
      "INFO:lda:<330> log likelihood: -14361975\n",
      "INFO:lda:<340> log likelihood: -14359389\n",
      "INFO:lda:<350> log likelihood: -14353319\n",
      "INFO:lda:<360> log likelihood: -14352142\n",
      "INFO:lda:<370> log likelihood: -14351251\n",
      "INFO:lda:<380> log likelihood: -14349833\n",
      "INFO:lda:<390> log likelihood: -14344871\n",
      "INFO:lda:<400> log likelihood: -14344722\n",
      "INFO:lda:<410> log likelihood: -14343263\n",
      "INFO:lda:<420> log likelihood: -14342113\n",
      "INFO:lda:<430> log likelihood: -14341273\n",
      "INFO:lda:<440> log likelihood: -14337901\n",
      "INFO:lda:<450> log likelihood: -14337956\n",
      "INFO:lda:<460> log likelihood: -14338429\n",
      "INFO:lda:<470> log likelihood: -14336537\n",
      "INFO:lda:<480> log likelihood: -14336498\n",
      "INFO:lda:<490> log likelihood: -14338615\n",
      "INFO:lda:<499> log likelihood: -14333184\n"
     ]
    }
   ],
   "source": [
    "import lda # if you get error pip install lda\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_topics = 20 # number of topics\n",
    "n_iter = 500 # number of iterations\n",
    "\n",
    "# vectorizer: ignore English stopwords & words that occur less than 5 times\n",
    "cvectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "cvz = cvectorizer.fit_transform(news)\n",
    "\n",
    "# train an LDA model\n",
    "lda_model = lda.LDA(n_topics=n_topics, n_iter=n_iter)\n",
    "X_topics = lda_model.fit_transform(cvz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing to 2-D with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 18846 samples in 0.018s...\n",
      "[t-SNE] Computed neighbors for 18846 samples in 13.503s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 18846 / 18846\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 86.948227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "\n",
    "# 20-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualzing groups and their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we do some setup work (import classes & functions, set params, etc.)\n",
    "import numpy as np\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "n_top_words = 5 # number of keywords we show\n",
    "\n",
    "# 20 colors\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we find the most likely topic for each news\n",
    "_lda_keys = []\n",
    "for i in xrange(X_topics.shape[0]):\n",
    "  _lda_keys +=  _topics[i].argmax(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top words for each topic\n",
    "topic_summaries = []\n",
    "topic_word = lda_model.topic_word_  # all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "  topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the news (each point representing one news)\n",
    "title = '20 newsgroups LDA viz'\n",
    "num_example = len(X_topics)\n",
    "\n",
    "plot_lda = bp.figure(plot_width=1400, plot_height=1100,\n",
    "                     title=title,\n",
    "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_lda.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
    "                 color=colormap[_lda_keys][:num_example],\n",
    "                 source=bp.ColumnDataSource({\n",
    "                   \"content\": news[:num_example],\n",
    "                   \"topic_key\": _lda_keys[:num_example]\n",
    "                   }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
